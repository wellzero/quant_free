{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3ba68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            bin  price_ratio_10         t1\n",
      "2020-09-23    1        0.109306 2020-09-23\n",
      "2020-09-24    1        0.113493 2020-09-24\n",
      "2020-09-25    1        0.118233 2020-09-25\n",
      "2020-09-28    1        0.130722 2020-09-28\n",
      "2020-09-29    1        0.107420 2020-09-29\n",
      "2020-09-30    1        0.088820 2020-09-30\n",
      "2020-10-01    1        0.064789 2020-10-01\n",
      "2020-10-02    1        0.070477 2020-10-02\n",
      "2020-10-05    1        0.035099 2020-10-05\n",
      "2020-10-06    1        0.060002 2020-10-06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from quant_free.dataset.us_equity_load import *\n",
    "from quant_free.utils.us_equity_utils import *\n",
    "from quant_free.factor.price import *\n",
    "\n",
    "symbol = 'TSM'\n",
    "# symbol = 'AAPL'\n",
    "# symbol = 'INTC'\n",
    "\n",
    "factor_name = 'Trend.csv'\n",
    "like = 'trend'\n",
    "\n",
    "# factor_name = 'Alpha101.csv'\n",
    "# like = 'alpha'\n",
    "\n",
    "thr = 0.00\n",
    "forward_period = 10\n",
    "start_date = get_json_config_value(\"training_start_date\")\n",
    "end_date = get_json_config_value(\"training_end_date\")\n",
    "market = 'us'\n",
    "\n",
    "factor = equity_tradedata_load_bt_dates(market, symbols = [symbol], start_date = start_date,\n",
    "                                end_date = end_date, column_option = \"all\", file_name = factor_name)[symbol]\n",
    "factor = factor.replace({True: 1, False: 0})\n",
    "factor = factor.loc[:, (factor != 0).any(axis=0)]\n",
    "# trnsX = factor.loc[:, ['alpha1', 'alpha2', 'alpha3', 'alpha4', 'alpha5', 'alpha6', 'alpha7', 'alpha8', 'alpha9', 'alpha10', 'alpha11', 'alpha12', 'alpha13', 'alpha14', 'alpha15']]\n",
    "trnsX = factor.filter(like=like).astype(np.float64)\n",
    "# print(trnsX.head(5))\n",
    "\n",
    "\n",
    "# price_ratio = PriceRatio(start_date, end_date, symbol = symbol, column_option = 'close', dir_option = 'xq')\n",
    "# y_data = price_ratio.price_ratio(periods = periods)\n",
    "y_data = factor.loc[:, f'ret_forward_{forward_period}']\n",
    "cont = pd.DataFrame(y_data.map(lambda x: 1 if x > thr else 0 if x < -thr else 0))\n",
    "cont = pd.concat([cont, y_data], axis = 1)\n",
    "cont.columns = ['bin', f'price_ratio_{forward_period}']\n",
    "cont['t1'] = cont.index\n",
    "\n",
    "print(cont.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ff206af6eeba8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:58:48.147610Z",
     "start_time": "2024-05-24T13:58:46.703787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob_score 0.7546485260770975\n",
      "oos_score 0.5573054873054873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from quant_free.finml.feature_importance import *\n",
    "\n",
    "forest = RandomForestClassifier(\n",
    "    criterion = 'entropy',\n",
    "    class_weight = 'balanced_subsample',\n",
    "    min_weight_fraction_leaf = 0.0,\n",
    "    random_state = 42,\n",
    "    n_estimators = 100,\n",
    "    max_features = 1,\n",
    "    oob_score = True,\n",
    "    n_jobs = 1\n",
    ")\n",
    "\n",
    "fit = forest.fit(X = trnsX, y = cont['bin'])\n",
    "oob_score = fit.oob_score_\n",
    "print(f\"oob_score {oob_score}\")\n",
    "\n",
    "from quant_free.finml.cross_validation.cross_validation import PurgedKFold, cross_val_score\n",
    "from quant_free.finml.feature_importance.importance import *\n",
    "cv_gen = PurgedKFold(\n",
    "    n_splits = 20, \n",
    "    samples_info_sets = cont['t1']\n",
    ")\n",
    "\n",
    "oos_score = cross_val_score(\n",
    "    forest, # base classifier\n",
    "    trnsX, # train features\n",
    "    cont['bin'], # train labels\n",
    "    cv_gen = cv_gen, # purged k fold cross validation class\n",
    "    scoring = accuracy_score # optimizing to accuracy score\n",
    ").mean()\n",
    "print(f\"oos_score {oos_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cb6e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oos_score 0.5622768222768223\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from quant_free.finml.feature_importance import *\n",
    "from quant_free.finml.cross_validation.cross_validation import PurgedKFold, cross_val_score\n",
    "\n",
    "cv_gen = PurgedKFold(\n",
    "    n_splits = 20, \n",
    "    samples_info_sets = cont['t1']\n",
    ")\n",
    "\n",
    "forest = XGBClassifier(\n",
    "                        # max_depth=3,                  # Maximum tree depth for base learners.\n",
    "                        learning_rate=0.1,            # Boosting learning rate (xgb's \"eta\")\n",
    "                        n_estimators=100,             # Number of boosted trees to fit.\n",
    "                        # silent=True,                  # Whether to print messages while running\n",
    "                        objective='binary:logistic',  # Task and objective or custom objective function\n",
    "                        booster='gbtree',             # Select booster: gbtree, gblinear or dart\n",
    "#                         tree_method='gpu_hist',\n",
    "                        n_jobs=-1,                    # Number of parallel threads\n",
    "                        gamma=0,                      # Min loss reduction for further splits\n",
    "                        min_child_weight=1,           # Min sum of sample weight(hessian) needed\n",
    "                        max_delta_step=0,             # Max delta step for each tree's weight estimation\n",
    "                        subsample=1,                  # Subsample ratio of training samples\n",
    "                        colsample_bytree=1,           # Subsample ratio of cols for each tree\n",
    "                        colsample_bylevel=1,          # Subsample ratio of cols for each split\n",
    "                        reg_alpha=0,                  # L1 regularization term on weights\n",
    "                        reg_lambda=1,                 # L2 regularization term on weights\n",
    "                        scale_pos_weight=1,           # Balancing class weights\n",
    "                        base_score=0.5,               # Initial prediction score; global bias\n",
    "                        random_state=42)              # random seed\n",
    "\n",
    "oos_score = cross_val_score(\n",
    "    forest, # base classifier\n",
    "    trnsX, # train features\n",
    "    cont['bin'], # train labels\n",
    "    cv_gen = cv_gen, # purged k fold cross validation class\n",
    "    scoring = accuracy_score # optimizing to accuracy score\n",
    ").mean()\n",
    "print(f\"oos_score {oos_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "045be8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: {'learning_rate': 0.1, 'min_impurity_decrease': 0, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.8}\n",
      "best_score: 0.48999721390431333\n",
      "best_estimator: GradientBoostingClassifier(max_features=1, min_impurity_decrease=0,\n",
      "                           min_samples_split=10, random_state=42,\n",
      "                           subsample=0.8)\n",
      "oos_score 0.5818509418509419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "forest = GradientBoostingClassifier(loss='log_loss',\n",
    "                                    learning_rate=0.1,\n",
    "                                    n_estimators=100,\n",
    "                                    subsample=1.0,\n",
    "                                    criterion='friedman_mse',\n",
    "                                    min_samples_split=2,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    # max_depth=3,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    # min_impurity_split=None,\n",
    "                                    init=None,\n",
    "                                    random_state=42,\n",
    "                                    max_features=1,\n",
    "                                    verbose=0,\n",
    "                                    max_leaf_nodes=None,\n",
    "                                    warm_start=False,\n",
    "                                    # presort='auto',\n",
    "                                    validation_fraction=0.1,\n",
    "                                    n_iter_no_change=None,\n",
    "                                    tol=0.0001)\n",
    "\n",
    "param_grid = dict(\n",
    "        learning_rate=[.005, .01, .1],\n",
    "        # max_depth=list(range(3, 13, 3)),\n",
    "        # max_features=['sqrt', .8, 1],\n",
    "        min_impurity_decrease=[0, .01],\n",
    "        min_samples_split=[2, 10, 50],\n",
    "        n_estimators=[150, 100],\n",
    "        subsample=[.8, 1])\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(forest,\n",
    "                  param_grid,\n",
    "                  # cv=accuracy_score,\n",
    "                  scoring='roc_auc',\n",
    "                  verbose=0,\n",
    "                  n_jobs=-1,\n",
    "                  return_train_score=True)\n",
    "gs.fit(X = trnsX, y = cont['bin'])\n",
    "\n",
    "print(f\"param: {gs.best_params_}\")\n",
    "print(f\"best_score: {gs.best_score_}\")\n",
    "print(f\"best_estimator: {gs.best_estimator_}\")\n",
    "\n",
    "from quant_free.finml.cross_validation.cross_validation import PurgedKFold, cross_val_score\n",
    "cv_gen = PurgedKFold(\n",
    "    n_splits = 20, \n",
    "    samples_info_sets = cont['t1']\n",
    ")\n",
    "oos_score = cross_val_score(\n",
    "    gs.best_estimator_, # base classifier\n",
    "    trnsX, # train features\n",
    "    cont['bin'], # train labels\n",
    "    cv_gen = cv_gen, # purged k fold cross validation class\n",
    "    scoring = accuracy_score # optimizing to accuracy score\n",
    ").mean()\n",
    "print(f\"oos_score {oos_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantfree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
